{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch.models.mtcnn import MTCNN\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"original_data\"\n",
    "processed_data_path = \"processed_data\"\n",
    "split_types = ['train', 'test', 'val']\n",
    "target_size = (380, 380)\n",
    "padding_coef = 0.3\n",
    "frame_step = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale_coef(w):\n",
    "    if w <= 300:\n",
    "        scale_coef = 2\n",
    "    elif w <= 1000:\n",
    "        scale_coef = 1\n",
    "    elif w <= 1900:\n",
    "        scale_coef = 0.5\n",
    "    else:\n",
    "        scale_coef = 0.33\n",
    "    return scale_coef\n",
    "\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, data_path, split=None, step=1):\n",
    "        self.data_path = data_path\n",
    "        self.split = split\n",
    "        self.step = step\n",
    "        \n",
    "        data = []\n",
    "        for split in split_types:\n",
    "            if self.split is not None and self.split != split:\n",
    "                continue\n",
    "            for path in os.listdir(os.path.join(data_path, split)):\n",
    "                if os.path.isdir(os.path.join(data_path, split, path)):\n",
    "                    for name in os.listdir(os.path.join(data_path, split, path)):\n",
    "                        data.append({'name':name, 'path':path, 'split':split})\n",
    "        data = pd.DataFrame(data)\n",
    "        self.data = data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        name, path, split = self.data.loc[index]\n",
    "        capture = cv2.VideoCapture(os.path.join(self.data_path, split, path, name))\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_w = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        scale_coef = get_scale_coef(frame_w)\n",
    "        vid = os.path.splitext(name)[0]\n",
    "        \n",
    "        frames = []\n",
    "        scaled_frames = []\n",
    "        for i in range(frame_count):\n",
    "            capture.grab()\n",
    "            success, frame = capture.retrieve()\n",
    "            if success and i%self.step == 0:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                scaled_frame = cv2.resize(frame, tuple([int(s*scale_coef) for s in frame.shape[1::-1]]))\n",
    "                frames.append(frame)\n",
    "                scaled_frames.append(scaled_frame)\n",
    "        return vid, frames, scaled_frames, scale_coef\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector():\n",
    "    def __init__(self, batch_size=16, device=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.detector = MTCNN(margin=0,thresholds=[0.85, 0.95, 0.95], device=device)\n",
    "    \n",
    "    def detect_faces(self, frames, scale_coef):\n",
    "        boxes = []\n",
    "        for i in range(math.ceil(len(frames) / self.batch_size)):\n",
    "            batch_boxes, *_ = self.detector.detect(frames[i*self.batch_size:(i + 1)*self.batch_size])\n",
    "            boxes += [(b/scale_coef).astype(int).tolist() if b is not None else None for b in batch_boxes]\n",
    "        return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame(frame, box, padding_coef):\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    w = x_max - x_min\n",
    "    h = y_max - y_min\n",
    "    w_p = int(w * padding_coef)\n",
    "    h_p = int(h * padding_coef)\n",
    "    crop = frame[max(0, y_min - h_p):y_max + h_p, max(0, x_min - w_p):x_max + w_p]\n",
    "    return crop\n",
    "\n",
    "def process_videos(dataset, processed_data_path, face_detector, padding_coef=0.3):\n",
    "    loader = DataLoader(dataset, collate_fn=lambda x: x)\n",
    "    crops_dir = os.path.join(processed_data_path, \"crops\")\n",
    "    os.makedirs(crops_dir, exist_ok=True)\n",
    "    \n",
    "    for item in tqdm(loader):\n",
    "        vid, frames, scaled_frames, scale_coef = item[0]\n",
    "        boxes = face_detector.detect_faces(scaled_frames, scale_coef)\n",
    "        \n",
    "        out_dir = os.path.join(crops_dir, vid)\n",
    "        os.makedirs(out_dir, exist_ok=True) \n",
    "        for i in range(len(frames)):\n",
    "            box = boxes[i]\n",
    "            if box is not None:\n",
    "                frame = frames[i]\n",
    "                crop = crop_frame(frame, box[0], padding_coef)\n",
    "                crop = cv2.resize(crop, target_size)\n",
    "                crop = cv2.cvtColor(crop, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(os.path.join(out_dir, \"{}.png\".format(i)), crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_crop_metadata(data_path, processed_data_path, split):\n",
    "    video_metadata = {}\n",
    "    for path in os.listdir(os.path.join(data_path, split)):\n",
    "        if os.path.isdir(os.path.join(data_path, split, path)):\n",
    "            with open(os.path.join(data_path, split, path, 'metadata.json'), 'r') as f:\n",
    "                metadata_part = json.load(f)\n",
    "                video_metadata.update(metadata_part)\n",
    "    \n",
    "    crops_metadata = []\n",
    "    for video_name in video_metadata:\n",
    "        label, *_ = video_metadata[video_name].values()\n",
    "        label = True if label == 'REAL' else False\n",
    "        vid = video_name.split('.')[0]\n",
    "        crops_path = os.path.join(processed_data_path, 'crops', vid)\n",
    "        for crop_name in os.listdir(crops_path):\n",
    "            cid = os.path.splitext(crop_name)[0]\n",
    "            crops_metadata.append({'vid':vid, 'cid':cid, 'label':label})\n",
    "    crops_metadata = pd.DataFrame(crops_metadata)\n",
    "    crops_metadata.to_csv(os.path.join(processed_data_path, '{}.csv'.format(split)),\n",
    "                          index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDataset(data_path, step=frame_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = FaceDetector(16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_videos(dataset, processed_data_path, face_detector, padding_coef=padding_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in split_types:\n",
    "    save_crop_metadata(data_path, processed_data_path, split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
